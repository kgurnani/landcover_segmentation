{"cells":[{"cell_type":"code","execution_count":null,"id":"vB4qserabZXf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15061,"status":"ok","timestamp":1722048057497,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"vB4qserabZXf","outputId":"880011be-132b-4f34-8268-c0101b9c5554"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"2Toq6xX73MuB","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2Toq6xX73MuB","outputId":"0c749b37-a165-4e95-b3ce-a045d3ac2e12"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Collecting torchtune\n","  Downloading torchtune-0.2.1-py3-none-any.whl.metadata (19 kB)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n","Collecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Collecting datasets (from torchtune)\n","  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.23.5)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.4.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.1.99)\n","Collecting tiktoken (from torchtune)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting blobfile>=2 (from torchtune)\n","  Downloading blobfile-2.1.1-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.10/dist-packages (from torchtune) (1.25.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtune) (4.66.4)\n","Collecting omegaconf (from torchtune)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting torchao==0.3.1 (from torchtune)\n","  Downloading torchao-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.1+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n","Collecting pycryptodomex~=3.8 (from blobfile>=2->torchtune)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (2.0.7)\n","Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (4.9.4)\n","Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (3.15.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting pyarrow>=15.0.0 (from datasets->torchtune)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets->torchtune)\n","  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting xxhash (from datasets->torchtune)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets->torchtune)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec (from torch>=1.10.0->torchmetrics)\n","  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (6.0.1)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->torchtune) (2024.5.15)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Downloading torchtune-0.2.1-py3-none-any.whl (350 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.6/350.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchao-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (409 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m423.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=a059ead50477df37f580d9c0041a2b97aa712acc1a4f03c5b01cf4430808c631\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: torchao, antlr4-python3-runtime, xxhash, torchinfo, requests, pycryptodomex, pyarrow, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, fsspec, einops, dill, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, blobfile, nvidia-cusolver-cu12, datasets, torchtune, torchmetrics\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.6.1\n","    Uninstalling fsspec-2024.6.1:\n","      Successfully uninstalled fsspec-2024.6.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 blobfile-2.1.1 datasets-2.20.0 dill-0.3.8 einops-0.8.0 fsspec-2024.5.0 lightning-utilities-0.11.6 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pyarrow-17.0.0 pycryptodomex-3.20.0 requests-2.32.3 tiktoken-0.7.0 torchao-0.3.1 torchinfo-1.8.0 torchmetrics-1.4.0.post0 torchtune-0.2.1 xxhash-3.4.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"9be810fdbaed41e981e1acd6412d7621","pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install -U torchinfo torchtune torchmetrics einops"]},{"cell_type":"code","execution_count":null,"id":"YOupkJnJTzpE","metadata":{"colab":{"background_save":true},"id":"YOupkJnJTzpE","outputId":"0608fe67-1184-4292-d7d5-5fd371518cf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting albumentations==1.4.10\n","  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: numpy<2,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (1.25.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (1.13.1)\n","Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (0.23.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (6.0.1)\n","Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (4.12.2)\n","Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (1.3.2)\n","Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (2.8.2)\n","Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (0.0.12)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.10) (4.10.0.84)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations==1.4.10) (2.0.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10) (2.20.1)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (3.3)\n","Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (9.4.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (2.34.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (2024.7.21)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.10) (0.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10) (3.5.0)\n","Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/161.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: albumentations\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.4.11\n","    Uninstalling albumentations-1.4.11:\n","      Successfully uninstalled albumentations-1.4.11\n","Successfully installed albumentations-1.4.10\n"]}],"source":["!pip install albumentations==1.4.10"]},{"cell_type":"code","execution_count":null,"id":"ADpNRFfzRbN4","metadata":{"colab":{"background_save":true},"id":"ADpNRFfzRbN4","outputId":"f72bd805-1857-45bc-b773-42a5f8ec3200"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mamba-ssm\n","  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting causal-conv1d\n","  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n","Collecting ninja (from mamba-ssm)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2024.5.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.82)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n","Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: mamba-ssm, causal-conv1d\n","  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323803485 sha256=cd8ee941b25398d90c135d3a180b5dc33e478c98ae4998b61749809beaff947a\n","  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n","  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp310-cp310-linux_x86_64.whl size=104684541 sha256=7406be22f70ba3bb956556f0f0ce04608b5ad00fc171df39b562c97dc757731d\n","  Stored in directory: /root/.cache/pip/wheels/e3/dd/4c/205f24e151736bd22f5980738dd10a19af6f093b6f4dcab006\n","Successfully built mamba-ssm causal-conv1d\n","Installing collected packages: ninja, causal-conv1d, mamba-ssm\n","Successfully installed causal-conv1d-1.4.0 mamba-ssm-2.2.2 ninja-1.11.1.1\n"]}],"source":["!pip install -U mamba-ssm causal-conv1d"]},{"cell_type":"code","execution_count":null,"id":"hKkY-CWOkYKE","metadata":{"colab":{"background_save":true},"id":"hKkY-CWOkYKE","outputId":"d453b676-d53f-480f-e836-13ffa1a771aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n","Collecting torch\n","  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.5.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Collecting triton==3.0.0 (from torch)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-cudnn-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.1\n","    Uninstalling triton-2.3.1:\n","      Successfully uninstalled triton-2.3.1\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n","    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n","      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.1+cu121\n","    Uninstalling torch-2.3.1+cu121:\n","      Successfully uninstalled torch-2.3.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\n","torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\n","torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 torch-2.4.0 triton-3.0.0\n"]}],"source":["!pip install -U torch"]},{"cell_type":"code","execution_count":null,"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","metadata":{"colab":{"background_save":true},"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","outputId":"cd32bcf6-4df6-46d5-d68d-42e6ca67cb1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, grad_output):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data.dataset import Dataset\n","from PIL import Image\n","import glob\n","import os\n","import torch.nn.functional as F\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from torchmetrics.classification import MulticlassJaccardIndex\n","import shutil\n","import cv2\n","import json\n","from einops.layers.torch import Rearrange, Reduce\n","from torch import Tensor\n","from einops import rearrange, repeat\n","from torchinfo import summary\n","from torchtune.modules import RMSNorm\n","from mamba_ssm import Mamba"]},{"cell_type":"code","execution_count":null,"id":"oP433x83Vt9H","metadata":{"colab":{"background_save":true},"id":"oP433x83Vt9H","outputId":"a52b7402-6a6e-4caf-af7d-027a52893050"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-07-27 02:43:49--  https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip\n","Resolving landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)... 195.78.67.65\n","Connecting to landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)|195.78.67.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1538212277 (1.4G) [application/zip]\n","Saving to: ‘landcover.ai.v1.zip’\n","\n","landcover.ai.v1.zip 100%[===================>]   1.43G  16.2MB/s    in 90s     \n","\n","2024-07-27 02:45:19 (16.3 MB/s) - ‘landcover.ai.v1.zip’ saved [1538212277/1538212277]\n","\n"]}],"source":["!wget https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip"]},{"cell_type":"code","execution_count":null,"id":"ezexmvBDWLlM","metadata":{"colab":{"background_save":true},"id":"ezexmvBDWLlM","outputId":"badb34a6-0064-4374-8f49-ee625b15dbca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  landcover.ai.v1.zip\n","   creating: landcover.ai.v1/images/\n","  inflating: landcover.ai.v1/images/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-D-c-2-4.tif  \n","   creating: landcover.ai.v1/masks/\n","  inflating: landcover.ai.v1/masks/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-D-c-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/masks/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/split.py  \n","  inflating: landcover.ai.v1/test.txt  \n","  inflating: landcover.ai.v1/train.txt  \n","  inflating: landcover.ai.v1/val.txt  \n"]}],"source":["!unzip landcover.ai.v1.zip -d landcover.ai.v1"]},{"cell_type":"code","execution_count":null,"id":"m9mqVGafXk5q","metadata":{"colab":{"background_save":true},"id":"m9mqVGafXk5q","outputId":"fa18e3e7-82d7-4d0a-842f-0ad9541919ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed M-33-20-D-c-4-2 1/41\n","Processed M-33-20-D-d-3-3 2/41\n","Processed M-33-32-B-b-4-4 3/41\n","Processed M-33-48-A-c-4-4 4/41\n","Processed M-33-7-A-d-2-3 5/41\n","Processed M-33-7-A-d-3-2 6/41\n","Processed M-34-32-B-a-4-3 7/41\n","Processed M-34-32-B-b-1-3 8/41\n","Processed M-34-5-D-d-4-2 9/41\n","Processed M-34-51-C-b-2-1 10/41\n","Processed M-34-51-C-d-4-1 11/41\n","Processed M-34-55-B-b-4-1 12/41\n","Processed M-34-56-A-b-1-4 13/41\n","Processed M-34-6-A-d-2-2 14/41\n","Processed M-34-65-D-a-4-4 15/41\n","Processed M-34-65-D-c-4-2 16/41\n","Processed M-34-65-D-d-4-1 17/41\n","Processed M-34-68-B-a-1-3 18/41\n","Processed M-34-77-B-c-2-3 19/41\n","Processed N-33-104-A-c-1-1 20/41\n","Processed N-33-119-C-c-3-3 21/41\n","Processed N-33-130-A-d-3-3 22/41\n","Processed N-33-130-A-d-4-4 23/41\n","Processed N-33-139-C-d-2-2 24/41\n","Processed N-33-139-C-d-2-4 25/41\n","Processed N-33-139-D-c-1-3 26/41\n","Processed N-33-60-D-c-4-2 27/41\n","Processed N-33-60-D-d-1-2 28/41\n","Processed N-33-96-D-d-1-1 29/41\n","Processed N-34-106-A-b-3-4 30/41\n","Processed N-34-106-A-c-1-3 31/41\n","Processed N-34-140-A-b-3-2 32/41\n","Processed N-34-140-A-b-4-2 33/41\n","Processed N-34-140-A-d-3-4 34/41\n","Processed N-34-140-A-d-4-2 35/41\n","Processed N-34-61-B-a-1-1 36/41\n","Processed N-34-66-C-c-4-3 37/41\n","Processed N-34-77-A-b-1-4 38/41\n","Processed N-34-94-A-b-2-4 39/41\n","Processed N-34-97-C-b-1-2 40/41\n","Processed N-34-97-D-c-2-4 41/41\n"]}],"source":["IMGS_DIR = \"./landcover.ai.v1/images\"\n","MASKS_DIR = \"./landcover.ai.v1/masks\"\n","OUTPUT_DIR = \"./landcover.ai.v1/output\"\n","\n","TARGET_SIZE = 512\n","\n","img_paths = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\n","mask_paths = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n","\n","img_paths.sort()\n","mask_paths.sort()\n","\n","os.makedirs(OUTPUT_DIR)\n","for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n","    img_filename = os.path.splitext(os.path.basename(img_path))[0]\n","    mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n","    img = cv2.imread(img_path)\n","    mask = cv2.imread(mask_path)\n","\n","    assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n","\n","    k = 0\n","    for y in range(0, img.shape[0], TARGET_SIZE):\n","        for x in range(0, img.shape[1], TARGET_SIZE):\n","            img_tile = img[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","            mask_tile = mask[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","\n","            if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n","                out_img_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}.tif\".format(img_filename, k)\n","                )\n","                cv2.imwrite(out_img_path, img_tile)\n","\n","                out_mask_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}_m.tif\".format(mask_filename, k)\n","                )\n","                cv2.imwrite(out_mask_path, mask_tile)\n","\n","            k += 1\n","\n","    print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"]},{"cell_type":"code","execution_count":null,"id":"GMVhfETqX3DI","metadata":{"colab":{"background_save":true},"id":"GMVhfETqX3DI","outputId":"cf6c0624-1cbc-4aa7-8af0-a0cb1ec39ee2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder 'landcover.ai.v1/train/image' created.\n","Folder 'landcover.ai.v1/train/label' created.\n","Folder 'landcover.ai.v1/val/image' created.\n","Folder 'landcover.ai.v1/val/label' created.\n","Folder 'landcover.ai.v1/test/image' created.\n","Folder 'landcover.ai.v1/test/label' created.\n","Train, Val, Test splits count\n","7470 1602 1602\n","Last item of each split\n","N-34-97-D-c-2-4_9 N-34-97-D-c-2-4_75 N-34-97-D-c-2-4_77\n","File copying completed.\n"]}],"source":["train_data_dir = \"landcover.ai.v1/train/image\"\n","train_label_dir = \"landcover.ai.v1/train/label\"\n","\n","val_data_dir = \"landcover.ai.v1/val/image\"\n","val_label_dir = \"landcover.ai.v1/val/label\"\n","\n","test_data_dir = \"landcover.ai.v1/test/image\"\n","test_label_dir = \"landcover.ai.v1/test/label\"\n","\n","paths = [\n","    train_data_dir,\n","    train_label_dir,\n","    val_data_dir,\n","    val_label_dir,\n","    test_data_dir,\n","    test_label_dir,\n","]\n","\n","for p in paths:\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","        print(f\"Folder '{p}' created.\")\n","    else:\n","        print(f\"Folder '{p}' already exists.\")\n","\n","\n","with open(\"landcover.ai.v1/train.txt\") as f:\n","    train_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/val.txt\") as f:\n","    val_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/test.txt\") as f:\n","    test_split = f.read().splitlines()\n","\n","print(\"Train, Val, Test splits count\")\n","print(len(train_split), len(val_split), len(test_split))\n","print(\"Last item of each split\")\n","print(train_split[-1], val_split[-1], test_split[-1])\n","\n","for i in train_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(train_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(train_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in val_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(val_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(val_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in test_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(test_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(test_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","print(\"File copying completed.\")"]},{"cell_type":"code","execution_count":null,"id":"a93df827-0e31-479c-8fa0-f506d92eee05","metadata":{"colab":{"background_save":true},"id":"a93df827-0e31-479c-8fa0-f506d92eee05","outputId":"de3078be-0151-422a-c43c-1e47f4ab2020"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"id":"fAXbMfuqeore","metadata":{"colab":{"background_save":true},"id":"fAXbMfuqeore"},"outputs":[],"source":["class PatchEmbedding(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.projection = nn.Sequential(\n","            nn.Conv2d(3, 1024, kernel_size=16, stride=16),\n","            Rearrange('b e (h) (w) -> b (h w) e'),\n","        )\n","        self.positions = nn.Parameter(torch.zeros(1, (512 // 16) ** 2, 1024))\n","        nn.init.trunc_normal_(self.positions, std=0.02)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.projection(x)\n","        x += self.positions\n","        return x\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.norm1 = RMSNorm(1024)\n","        self.attn = nn.MultiheadAttention(1024, 16, batch_first=True, dropout=0.0)\n","        self.norm2 = RMSNorm(1024)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(1024, 1024 * 2),\n","            nn.SiLU(),\n","            nn.Dropout(0.0),\n","            nn.Linear(1024 * 2, 1024)\n","        )\n","        self.dropout = nn.Dropout(0.0)\n","\n","    def forward(self, x):\n","        x = x + self.dropout(self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0])\n","        x = x + self.dropout(self.mlp(self.norm2(x)))\n","        return x\n","\n","class MambaBlock(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.norm1 = RMSNorm(1024)\n","        self.mamba = Mamba(d_model=1024)\n","        self.norm2 = RMSNorm(1024)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(1024, 1024 * 2),\n","            nn.SiLU(),\n","            nn.Dropout(0.0),\n","            nn.Linear(1024 * 2, 1024)\n","        )\n","        self.dropout = nn.Dropout(0.0)\n","\n","    def forward(self, x):\n","        x = x + self.dropout(self.mamba(self.norm1(x)))\n","        x = x + self.dropout(self.mlp(self.norm2(x)))\n","        return x\n","\n","class SETRM(nn.Module):\n","    def __init__(self, num_transformer_layers, mamba_to_transformer_ratio):\n","        super().__init__()\n","\n","        self.patch_embed = PatchEmbedding()\n","\n","        self.num_transformer_layers = num_transformer_layers\n","        self.mamba_to_transformer_ratio = mamba_to_transformer_ratio\n","\n","        self.transformer_layers = nn.ModuleList()\n","        self.mamba_layers = nn.ModuleList()\n","\n","        self.final_transformer = TransformerBlock()\n","\n","        for i in range(num_transformer_layers):\n","            self.transformer_layers.append(TransformerBlock())\n","\n","        for i in range(num_transformer_layers * mamba_to_transformer_ratio):\n","            self.mamba_layers.append(MambaBlock())\n","\n","        self.decoder_1 = nn.Sequential(\n","            nn.Conv2d(1024, 512, 3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_2 = nn.Sequential(\n","            nn.Conv2d(512, 256, 3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_3 = nn.Sequential(\n","            nn.Conv2d(256, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_4 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.final_out = nn.Conv2d(64, 5, 3, padding=1)\n","\n","    def forward(self, x):\n","        x = self.patch_embed(x)\n","\n","        for i in range(len(self.transformer_layers)):\n","            x = self.transformer_layers[i](x)\n","            if len(self.mamba_layers) > 0:\n","                for j in range(i * self.mamba_to_transformer_ratio, (i * self.mamba_to_transformer_ratio) + self.mamba_to_transformer_ratio):\n","                    x = self.mamba_layers[j](x)\n","\n","        x = self.final_transformer(x)\n","\n","        x = rearrange(x, \"b (h w) c -> b c h w\", h = 512 // 16)\n","\n","        x = self.decoder_1(x)\n","        x = self.decoder_2(x)\n","        x = self.decoder_3(x)\n","        x = self.decoder_4(x)\n","\n","        x = self.final_out(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"56766017-1a95-459c-a631-f70d598a596e","metadata":{"colab":{"background_save":true},"id":"56766017-1a95-459c-a631-f70d598a596e"},"outputs":[],"source":["def preprocess_data(image, mask, train):\n","    if train:\n","        image_transforms = A.Compose(\n","            [\n","                A.OneOf([\n","                    A.ToGray(),\n","                    A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=3, val_shift_limit=3),\n","                    A.RandomBrightnessContrast(brightness_limit=0.01, contrast_limit=0.01, brightness_by_max=False)\n","                ], p=0.2),\n","                A.Normalize(),\n","                ToTensorV2()\n","            ]\n","        )\n","    else:\n","        image_transforms = A.Compose(\n","            [\n","                A.Normalize(),\n","                ToTensorV2()\n","            ]\n","        )\n","\n","    image = image_transforms(image=image)\n","    image = image['image']\n","\n","    mask = torch.from_numpy(mask)\n","    mask = torch.permute(mask, (2, 0, 1))\n","    mask = mask[0]\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":null,"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","metadata":{"colab":{"background_save":true},"id":"abda32f1-3087-4143-9766-97b4a32dc3c6"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, image_paths, target_paths, preprocess_fn, train=False):\n","        self.image_paths = image_paths\n","        self.target_paths = target_paths\n","        self.preprocess_fn = preprocess_fn\n","        self.train = train\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.image_paths[index])\n","        mask = Image.open(self.target_paths[index])\n","\n","        return self.preprocess_fn(np.array(image), np.array(mask, dtype=np.int8), train=self.train)\n","\n","    def __len__(self):\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":null,"id":"Ht9eqFxI7HaF","metadata":{"colab":{"background_save":true},"id":"Ht9eqFxI7HaF"},"outputs":[],"source":["class DiceLoss(nn.Module):\n","    \"\"\"Dice Loss PyTorch\n","        Created by: Zhang Shuai\n","        Email: shuaizzz666@gmail.com\n","        dice_loss = 1 - 2*p*t / (p^2 + t^2). p and t represent predict and target.\n","    Args:\n","        weight: An array of shape [C,]\n","        predict: A float32 tensor of shape [N, C, *], for Semantic segmentation task is [N, C, H, W]\n","        target: A int64 tensor of shape [N, *], for Semantic segmentation task is [N, H, W]\n","    Return:\n","        diceloss\n","    \"\"\"\n","    def __init__(self, weight=None):\n","        super(DiceLoss, self).__init__()\n","        if weight is not None:\n","            weight = torch.Tensor(weight)\n","            self.weight = weight / torch.sum(weight) # Normalized weight\n","        self.smooth = 1e-5\n","\n","    def forward(self, predict, target):\n","        N, C = predict.size()[:2]\n","        predict = predict.view(N, C, -1) # (N, C, *)\n","        target = target.view(N, 1, -1) # (N, 1, *)\n","\n","        predict = F.softmax(predict, dim=1) # (N, C, *) ==> (N, C, *)\n","        ## convert target(N, 1, *) into one hot vector (N, C, *)\n","        target_onehot = torch.zeros(predict.size()).cuda()  # (N, 1, *) ==> (N, C, *)\n","        target_onehot.scatter_(1, target, 1)  # (N, C, *)\n","\n","        intersection = torch.sum(predict * target_onehot, dim=2)  # (N, C)\n","        union = torch.sum(predict.pow(2), dim=2) + torch.sum(target_onehot, dim=2)  # (N, C)\n","        ## p^2 + t^2 >= 2*p*t, target_onehot^2 == target_onehot\n","        dice_coef = (2 * intersection + self.smooth) / (union + self.smooth)  # (N, C)\n","\n","        if hasattr(self, 'weight'):\n","            if self.weight.type() != predict.type():\n","                self.weight = self.weight.type_as(predict)\n","                dice_coef = dice_coef * self.weight * C  # (N, C)\n","        dice_loss = 1 - torch.mean(dice_coef)  # 1\n","\n","        return dice_loss"]},{"cell_type":"code","execution_count":null,"id":"6pOxcCZN7IaI","metadata":{"colab":{"background_save":true},"id":"6pOxcCZN7IaI"},"outputs":[],"source":["class CEPlusDiceLoss(nn.Module):\n","    def __init__(self):\n","        super(CEPlusDiceLoss, self).__init__()\n","        self.dice_loss = DiceLoss()\n","        self.ce_loss = nn.CrossEntropyLoss()\n","\n","    def forward(self, predict, target):\n","        dice = self.dice_loss(predict, target.to(torch.int64))\n","        ce = self.ce_loss(predict, target.long())\n","\n","        total = dice + ce\n","\n","        return total"]},{"cell_type":"code","execution_count":null,"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","metadata":{"colab":{"background_save":true},"id":"699f2149-d1d7-4d08-bbef-019da2ab4135"},"outputs":[],"source":["batch_size = 8\n","num_epochs = 25\n","num_classes = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","show_summary = True\n","experiment_name = \"12t-0m\"\n","run = 2"]},{"cell_type":"code","execution_count":null,"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","metadata":{"colab":{"background_save":true},"id":"e565ed5e-add1-4153-bf27-f276fc5717bd"},"outputs":[],"source":["train_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/image\", \"*.tif\"))\n","train_img_paths = sorted(train_img_paths)\n","\n","train_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/label\", \"*.tif\"))\n","train_mask_paths = sorted(train_mask_paths)\n","\n","val_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/image\", \"*.tif\"))\n","val_img_paths = sorted(val_img_paths)\n","\n","val_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/label\", \"*.tif\"))\n","val_mask_paths = sorted(val_mask_paths)"]},{"cell_type":"code","execution_count":null,"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","metadata":{"colab":{"background_save":true},"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5"},"outputs":[],"source":["train_dataset = CustomDataset(\n","    image_paths=train_img_paths,\n","    target_paths=train_mask_paths,\n","    preprocess_fn=preprocess_data,\n","    train=True\n",")\n","val_dataset = CustomDataset(\n","    image_paths=val_img_paths,\n","    target_paths=val_mask_paths,\n","    preprocess_fn=preprocess_data,\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","metadata":{"colab":{"background_save":true},"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe"},"outputs":[],"source":["model = SETRM(num_transformer_layers=12, mamba_to_transformer_ratio=0).to(device)\n","loss_fn = CEPlusDiceLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.000001, weight_decay=0.0001)\n","metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":null,"id":"VgC2dd2u8BeM","metadata":{"colab":{"background_save":true},"id":"VgC2dd2u8BeM","outputId":"d79cbef9-6e16-4b25-d0d0-c21e84972548"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-21-d05daea56d75>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_model-{experiment_name}-run-{run - 1}.pth\"))\n"]},{"name":"stdout","output_type":"stream","text":["Loading model\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-21-d05daea56d75>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  optimizer.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_opt-{experiment_name}-run-{run - 1}.pth\"))\n"]},{"name":"stdout","output_type":"stream","text":["Loading optimizer\n"]}],"source":["if run > 1:\n","    model.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_model-{experiment_name}-run-{run - 1}.pth\"))\n","    print(\"Loading model\")\n","    optimizer.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_opt-{experiment_name}-run-{run - 1}.pth\"))\n","    print(\"Loading optimizer\")"]},{"cell_type":"code","execution_count":null,"id":"89a861fb-e509-44a8-b625-f072f40b67be","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"89a861fb-e509-44a8-b625-f072f40b67be","outputId":"86f3b5a2-5a41-4cad-b4ae-e2a86aa86a00"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:28<00:00,  1.70s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0305\n","Train IoU: 0.5198\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:09<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9924\n","Validation IoU: 0.4713\n","-----------------------------\n","Epoch 2/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:34<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0170\n","Train IoU: 0.5241\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9848\n","Validation IoU: 0.4869\n","-----------------------------\n","Epoch 3/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:35<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0169\n","Train IoU: 0.5179\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9924\n","Validation IoU: 0.4816\n","-----------------------------\n","Epoch 4/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:34<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0002\n","Train IoU: 0.5278\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:09<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9786\n","Validation IoU: 0.4894\n","-----------------------------\n","Epoch 5/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:33<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9983\n","Train IoU: 0.5331\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:09<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9683\n","Validation IoU: 0.4897\n","-----------------------------\n","Epoch 6/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:33<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9914\n","Train IoU: 0.5365\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9643\n","Validation IoU: 0.4867\n","-----------------------------\n","Epoch 7/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:35<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9810\n","Train IoU: 0.5378\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:09<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9528\n","Validation IoU: 0.4903\n","-----------------------------\n","Epoch 8/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:33<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9715\n","Train IoU: 0.5440\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9549\n","Validation IoU: 0.4990\n","-----------------------------\n","Epoch 9/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9711\n","Train IoU: 0.5427\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9346\n","Validation IoU: 0.5002\n","-----------------------------\n","Epoch 10/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:35<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9618\n","Train IoU: 0.5462\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9559\n","Validation IoU: 0.4870\n","-----------------------------\n","Epoch 11/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:38<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9570\n","Train IoU: 0.5477\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9498\n","Validation IoU: 0.5003\n","-----------------------------\n","Epoch 12/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:35<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9529\n","Train IoU: 0.5530\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:09<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9349\n","Validation IoU: 0.5059\n","-----------------------------\n","Epoch 13/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:35<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9516\n","Train IoU: 0.5575\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9349\n","Validation IoU: 0.4996\n","-----------------------------\n","Epoch 14/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:34<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9404\n","Train IoU: 0.5565\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9276\n","Validation IoU: 0.5018\n","-----------------------------\n","Epoch 15/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9401\n","Train IoU: 0.5599\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9225\n","Validation IoU: 0.5034\n","-----------------------------\n","Epoch 16/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9415\n","Train IoU: 0.5585\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9312\n","Validation IoU: 0.4988\n","-----------------------------\n","Epoch 17/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9249\n","Train IoU: 0.5647\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.55it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9232\n","Validation IoU: 0.5068\n","-----------------------------\n","Epoch 18/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9219\n","Train IoU: 0.5632\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9277\n","Validation IoU: 0.5019\n","-----------------------------\n","Epoch 19/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:38<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9221\n","Train IoU: 0.5655\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9134\n","Validation IoU: 0.5101\n","-----------------------------\n","Epoch 20/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:38<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9147\n","Train IoU: 0.5716\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9075\n","Validation IoU: 0.5146\n","-----------------------------\n","Epoch 21/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9178\n","Train IoU: 0.5684\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9032\n","Validation IoU: 0.5133\n","-----------------------------\n","Epoch 22/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:37<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9141\n","Train IoU: 0.5707\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9241\n","Validation IoU: 0.5143\n","-----------------------------\n","Epoch 23/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:37<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9051\n","Train IoU: 0.5779\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9029\n","Validation IoU: 0.5212\n","-----------------------------\n","Epoch 24/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [26:36<00:00,  1.71s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9006\n","Train IoU: 0.5800\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [02:10<00:00,  1.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.9130\n","Validation IoU: 0.5162\n","-----------------------------\n","Epoch 25/25:\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining:   0%|          | 0/934 [00:00<?, ?it/s]"]}],"source":["epoch_train_loss = []\n","epoch_train_iou = []\n","epoch_val_loss = []\n","epoch_val_iou = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n","\n","    model.train()\n","    train_loss = 0\n","    train_iou = 0\n","\n","    for images, masks in tqdm(train_loader, desc=\"Training\"):\n","        images, masks = images.to(device), masks.to(device)\n","        outputs = model(images)\n","        loss = loss_fn(outputs, masks)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_iou += metric(outputs, masks)\n","\n","    train_loss = train_loss / len(train_loader)\n","    train_iou = train_iou / len(train_loader)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_train_iou.append(train_iou)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Train IoU: {train_iou:.4f}\")\n","\n","    model.eval()\n","    val_loss = 0\n","    val_iou = 0\n","\n","    with torch.inference_mode():\n","        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n","            images, masks = images.to(device), masks.to(device)\n","\n","            outputs = model(images)\n","            loss = loss_fn(outputs, masks)\n","\n","            val_loss += loss.item()\n","            val_iou += metric(outputs, masks)\n","\n","    val_loss = val_loss / len(val_loader)\n","    val_iou = val_iou / len(val_loader)\n","\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_iou.append(val_iou)\n","\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation IoU: {val_iou:.4f}\")\n","    print(\"-----------------------------\")\n","\n","torch.save(model.state_dict(), f\"/content/drive/MyDrive/landcover_seg_model-{experiment_name}-run-{run}.pth\")\n","torch.save(optimizer.state_dict(), f\"/content/drive/MyDrive/landcover_seg_opt-{experiment_name}-run-{run}.pth\")\n","\n","training_stats = {\n","    \"train_loss\": epoch_train_loss,\n","    \"train_iou\": [el.item() for el in epoch_train_iou],\n","    \"val_loss\": epoch_val_loss,\n","    \"val_iou\": [el.item() for el in epoch_val_iou]\n","}\n","\n","with open(f\"/content/drive/MyDrive/train-stats-{experiment_name}-run-{run}.json\", \"w\") as outfile:\n","    json.dump(training_stats, outfile)"]},{"cell_type":"code","execution_count":null,"id":"G4DD9sWN3Ao4","metadata":{"id":"G4DD9sWN3Ao4"},"outputs":[],"source":["if show_summary:\n","    print(summary(model, input_size=(1, 3, 512, 512)))"]},{"cell_type":"code","execution_count":null,"id":"cgpcI20j1bUO","metadata":{"id":"cgpcI20j1bUO"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}