{"cells":[{"cell_type":"code","execution_count":null,"id":"vB4qserabZXf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25342,"status":"ok","timestamp":1721053745525,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"vB4qserabZXf","outputId":"b10e4e8e-3820-4ae0-e8f0-8c6666e1b99b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"2Toq6xX73MuB","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":69081,"status":"ok","timestamp":1721053814603,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"2Toq6xX73MuB","outputId":"ffdd8d00-d871-428a-9933-e536c07d5e56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Collecting torchtune\n","  Downloading torchtune-0.1.1-py3-none-any.whl (210 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchmetrics\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets (from torchtune)\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.23.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.4.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtune) (0.1.99)\n","Collecting tiktoken (from torchtune)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting blobfile>=2 (from torchtune)\n","  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtune) (4.66.4)\n","Collecting omegaconf (from torchtune)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchao==0.1 (from torchtune)\n","  Downloading torchao-0.1-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchao==0.1->torchtune) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchao==0.1->torchtune) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchao==0.1->torchtune) (24.1)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.5-py3-none-any.whl (26 kB)\n","Collecting pycryptodomex~=3.8 (from blobfile>=2->torchtune)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (2.0.7)\n","Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (4.9.4)\n","Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile>=2->torchtune) (3.15.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchao==0.1->torchtune) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchao==0.1->torchtune) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchao==0.1->torchtune) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchao==0.1->torchtune) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchao==0.1->torchtune)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchao==0.1->torchtune) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchao==0.1->torchtune)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyarrow>=15.0.0 (from datasets->torchtune)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets->torchtune)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets->torchtune)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets->torchtune)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->torchtune) (6.0.1)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->torchtune) (2024.5.15)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->torchtune) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->torchtune) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchao==0.1->torchtune) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->torchtune) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchao==0.1->torchtune) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=f67f9a796ac69efc71145dcb419b128e9e9eda2a79a6de05578d6c87815100eb\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, xxhash, torchinfo, requests, pycryptodomex, pyarrow, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, einops, dill, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, blobfile, nvidia-cusolver-cu12, datasets, torchmetrics, torchao, torchtune\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 blobfile-2.1.1 datasets-2.20.0 dill-0.3.8 einops-0.8.0 lightning-utilities-0.11.5 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pyarrow-16.1.0 pycryptodomex-3.20.0 requests-2.32.3 tiktoken-0.7.0 torchao-0.1 torchinfo-1.8.0 torchmetrics-1.4.0.post0 torchtune-0.1.1 xxhash-3.4.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"19beb69dde88429ba3540edabe251651","pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install -U torchinfo torchtune torchmetrics einops"]},{"cell_type":"code","execution_count":null,"id":"ADpNRFfzRbN4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32224,"status":"ok","timestamp":1721053846807,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"ADpNRFfzRbN4","outputId":"e6cda267-3bb0-4587-d36e-54c936f2588d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mamba-ssm\n","  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting causal-conv1d\n","  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n","Collecting ninja (from mamba-ssm)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.82)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n","Building wheels for collected packages: mamba-ssm, causal-conv1d\n","  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323803485 sha256=cd8ee941b25398d90c135d3a180b5dc33e478c98ae4998b61749809beaff947a\n","  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n","  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp310-cp310-linux_x86_64.whl size=104684541 sha256=7406be22f70ba3bb956556f0f0ce04608b5ad00fc171df39b562c97dc757731d\n","  Stored in directory: /root/.cache/pip/wheels/e3/dd/4c/205f24e151736bd22f5980738dd10a19af6f093b6f4dcab006\n","Successfully built mamba-ssm causal-conv1d\n","Installing collected packages: ninja, causal-conv1d, mamba-ssm\n","Successfully installed causal-conv1d-1.4.0 mamba-ssm-2.2.2 ninja-1.11.1.1\n"]}],"source":["!pip install -U mamba-ssm causal-conv1d"]},{"cell_type":"code","execution_count":null,"id":"hKkY-CWOkYKE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56373,"status":"ok","timestamp":1721053903159,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"hKkY-CWOkYKE","outputId":"dee8614f-ddf6-47a0-de2e-a684ce001e56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Collecting torch\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Collecting triton==2.3.1 (from torch)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: triton, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.3.1 triton-2.3.1\n"]}],"source":["!pip install -U torch"]},{"cell_type":"code","execution_count":null,"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","metadata":{"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data.dataset import Dataset\n","from PIL import Image\n","import glob\n","import os\n","import torch.nn.functional as F\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from torchmetrics.classification import MulticlassJaccardIndex\n","import shutil\n","import cv2\n","import json\n","from einops.layers.torch import Rearrange, Reduce\n","from torch import Tensor\n","from einops import rearrange, repeat\n","from torchinfo import summary\n","from torchtune.modules import RMSNorm\n","from mamba_ssm import Mamba"]},{"cell_type":"code","execution_count":null,"id":"oP433x83Vt9H","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105646,"status":"ok","timestamp":1721054015916,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"oP433x83Vt9H","outputId":"7c4511da-c202-41db-aee9-d3dd141a9a2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-07-15 14:31:49--  https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip\n","Resolving landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)... 195.78.67.65\n","Connecting to landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)|195.78.67.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1538212277 (1.4G) [application/zip]\n","Saving to: ‘landcover.ai.v1.zip’\n","\n","landcover.ai.v1.zip 100%[===================>]   1.43G  14.5MB/s    in 1m 44s  \n","\n","2024-07-15 14:33:34 (14.1 MB/s) - ‘landcover.ai.v1.zip’ saved [1538212277/1538212277]\n","\n"]}],"source":["!wget https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip"]},{"cell_type":"code","execution_count":null,"id":"ezexmvBDWLlM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11395,"status":"ok","timestamp":1721054027307,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"ezexmvBDWLlM","outputId":"66d9fe10-222f-48f6-e506-b263f7c79ed4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  landcover.ai.v1.zip\n","   creating: landcover.ai.v1/images/\n","  inflating: landcover.ai.v1/images/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-D-c-2-4.tif  \n","   creating: landcover.ai.v1/masks/\n","  inflating: landcover.ai.v1/masks/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-D-c-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/masks/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/split.py  \n","  inflating: landcover.ai.v1/test.txt  \n","  inflating: landcover.ai.v1/train.txt  \n","  inflating: landcover.ai.v1/val.txt  \n"]}],"source":["!unzip landcover.ai.v1.zip -d landcover.ai.v1"]},{"cell_type":"code","execution_count":null,"id":"m9mqVGafXk5q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274490,"status":"ok","timestamp":1721054301776,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"m9mqVGafXk5q","outputId":"6437df17-6e65-45b1-b37f-1bf0596742a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processed M-33-20-D-c-4-2 1/41\n","Processed M-33-20-D-d-3-3 2/41\n","Processed M-33-32-B-b-4-4 3/41\n","Processed M-33-48-A-c-4-4 4/41\n","Processed M-33-7-A-d-2-3 5/41\n","Processed M-33-7-A-d-3-2 6/41\n","Processed M-34-32-B-a-4-3 7/41\n","Processed M-34-32-B-b-1-3 8/41\n","Processed M-34-5-D-d-4-2 9/41\n","Processed M-34-51-C-b-2-1 10/41\n","Processed M-34-51-C-d-4-1 11/41\n","Processed M-34-55-B-b-4-1 12/41\n","Processed M-34-56-A-b-1-4 13/41\n","Processed M-34-6-A-d-2-2 14/41\n","Processed M-34-65-D-a-4-4 15/41\n","Processed M-34-65-D-c-4-2 16/41\n","Processed M-34-65-D-d-4-1 17/41\n","Processed M-34-68-B-a-1-3 18/41\n","Processed M-34-77-B-c-2-3 19/41\n","Processed N-33-104-A-c-1-1 20/41\n","Processed N-33-119-C-c-3-3 21/41\n","Processed N-33-130-A-d-3-3 22/41\n","Processed N-33-130-A-d-4-4 23/41\n","Processed N-33-139-C-d-2-2 24/41\n","Processed N-33-139-C-d-2-4 25/41\n","Processed N-33-139-D-c-1-3 26/41\n","Processed N-33-60-D-c-4-2 27/41\n","Processed N-33-60-D-d-1-2 28/41\n","Processed N-33-96-D-d-1-1 29/41\n","Processed N-34-106-A-b-3-4 30/41\n","Processed N-34-106-A-c-1-3 31/41\n","Processed N-34-140-A-b-3-2 32/41\n","Processed N-34-140-A-b-4-2 33/41\n","Processed N-34-140-A-d-3-4 34/41\n","Processed N-34-140-A-d-4-2 35/41\n","Processed N-34-61-B-a-1-1 36/41\n","Processed N-34-66-C-c-4-3 37/41\n","Processed N-34-77-A-b-1-4 38/41\n","Processed N-34-94-A-b-2-4 39/41\n","Processed N-34-97-C-b-1-2 40/41\n","Processed N-34-97-D-c-2-4 41/41\n"]}],"source":["IMGS_DIR = \"./landcover.ai.v1/images\"\n","MASKS_DIR = \"./landcover.ai.v1/masks\"\n","OUTPUT_DIR = \"./landcover.ai.v1/output\"\n","\n","TARGET_SIZE = 512\n","\n","img_paths = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\n","mask_paths = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n","\n","img_paths.sort()\n","mask_paths.sort()\n","\n","os.makedirs(OUTPUT_DIR)\n","for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n","    img_filename = os.path.splitext(os.path.basename(img_path))[0]\n","    mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n","    img = cv2.imread(img_path)\n","    mask = cv2.imread(mask_path)\n","\n","    assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n","\n","    k = 0\n","    for y in range(0, img.shape[0], TARGET_SIZE):\n","        for x in range(0, img.shape[1], TARGET_SIZE):\n","            img_tile = img[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","            mask_tile = mask[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","\n","            if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n","                out_img_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}.tif\".format(img_filename, k)\n","                )\n","                cv2.imwrite(out_img_path, img_tile)\n","\n","                out_mask_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}_m.tif\".format(mask_filename, k)\n","                )\n","                cv2.imwrite(out_mask_path, mask_tile)\n","\n","            k += 1\n","\n","    print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"]},{"cell_type":"code","execution_count":null,"id":"GMVhfETqX3DI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14241,"status":"ok","timestamp":1721054316013,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"GMVhfETqX3DI","outputId":"ca92c13d-58d6-451b-8062-76a977e6ffce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder 'landcover.ai.v1/train/image' created.\n","Folder 'landcover.ai.v1/train/label' created.\n","Folder 'landcover.ai.v1/val/image' created.\n","Folder 'landcover.ai.v1/val/label' created.\n","Folder 'landcover.ai.v1/test/image' created.\n","Folder 'landcover.ai.v1/test/label' created.\n","Train, Val, Test splits count\n","7470 1602 1602\n","Last item of each split\n","N-34-97-D-c-2-4_9 N-34-97-D-c-2-4_75 N-34-97-D-c-2-4_77\n","File copying completed.\n"]}],"source":["train_data_dir = \"landcover.ai.v1/train/image\"\n","train_label_dir = \"landcover.ai.v1/train/label\"\n","\n","val_data_dir = \"landcover.ai.v1/val/image\"\n","val_label_dir = \"landcover.ai.v1/val/label\"\n","\n","test_data_dir = \"landcover.ai.v1/test/image\"\n","test_label_dir = \"landcover.ai.v1/test/label\"\n","\n","paths = [\n","    train_data_dir,\n","    train_label_dir,\n","    val_data_dir,\n","    val_label_dir,\n","    test_data_dir,\n","    test_label_dir,\n","]\n","\n","for p in paths:\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","        print(f\"Folder '{p}' created.\")\n","    else:\n","        print(f\"Folder '{p}' already exists.\")\n","\n","\n","with open(\"landcover.ai.v1/train.txt\") as f:\n","    train_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/val.txt\") as f:\n","    val_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/test.txt\") as f:\n","    test_split = f.read().splitlines()\n","\n","print(\"Train, Val, Test splits count\")\n","print(len(train_split), len(val_split), len(test_split))\n","print(\"Last item of each split\")\n","print(train_split[-1], val_split[-1], test_split[-1])\n","\n","for i in train_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(train_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(train_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in val_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(val_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(val_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in test_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(test_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(test_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","print(\"File copying completed.\")"]},{"cell_type":"code","execution_count":null,"id":"a93df827-0e31-479c-8fa0-f506d92eee05","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1721073695070,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"a93df827-0e31-479c-8fa0-f506d92eee05","outputId":"91f829ab-ce78-442c-d844-3b3c85766d89"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"id":"fAXbMfuqeore","metadata":{"id":"fAXbMfuqeore"},"outputs":[],"source":["class PatchEmbedding(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.projection = nn.Sequential(\n","            nn.Conv2d(3, 1024, kernel_size=16, stride=16),\n","            Rearrange('b e (h) (w) -> b (h w) e'),\n","        )\n","        self.positions = nn.Parameter(torch.zeros(1, (512 // 16) ** 2, 1024))\n","        nn.init.trunc_normal_(self.positions, std=0.02)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.projection(x)\n","        x += self.positions\n","        return x\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.norm1 = RMSNorm(1024)\n","        self.attn = nn.MultiheadAttention(1024, 16, batch_first=True, dropout=0.0)\n","        self.norm2 = RMSNorm(1024)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(1024, 1024 * 2),\n","            nn.SiLU(),\n","            nn.Dropout(0.0),\n","            nn.Linear(1024 * 2, 1024)\n","        )\n","        self.dropout = nn.Dropout(0.0)\n","\n","    def forward(self, x):\n","        x = x + self.dropout(self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0])\n","        x = x + self.dropout(self.mlp(self.norm2(x)))\n","        return x\n","\n","class MambaBlock(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.norm1 = RMSNorm(1024)\n","        self.mamba = Mamba(d_model=1024)\n","        self.norm2 = RMSNorm(1024)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(1024, 1024 * 2),\n","            nn.SiLU(),\n","            nn.Dropout(0.0),\n","            nn.Linear(1024 * 2, 1024)\n","        )\n","        self.dropout = nn.Dropout(0.0)\n","\n","    def forward(self, x):\n","        x = x + self.dropout(self.mamba(self.norm1(x)))\n","        x = x + self.dropout(self.mlp(self.norm2(x)))\n","        return x\n","\n","class SETRM(nn.Module):\n","    def __init__(self, num_transformer_layers, mamba_to_transformer_ratio):\n","        super().__init__()\n","\n","        self.patch_embed = PatchEmbedding()\n","\n","        self.num_transformer_layers = num_transformer_layers\n","        self.mamba_to_transformer_ratio = mamba_to_transformer_ratio\n","\n","        self.transformer_layers = nn.ModuleList()\n","        self.mamba_layers = nn.ModuleList()\n","\n","        self.final_transformer = TransformerBlock()\n","\n","        for i in range(num_transformer_layers):\n","            self.transformer_layers.append(TransformerBlock())\n","\n","        for i in range(num_transformer_layers * mamba_to_transformer_ratio):\n","            self.mamba_layers.append(MambaBlock())\n","\n","        self.decoder_1 = nn.Sequential(\n","            nn.Conv2d(1024, 512, 3, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_2 = nn.Sequential(\n","            nn.Conv2d(512, 256, 3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_3 = nn.Sequential(\n","            nn.Conv2d(256, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.decoder_4 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.SiLU(),\n","            nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n","        )\n","\n","        self.final_out = nn.Conv2d(64, 5, 3, padding=1)\n","\n","    def forward(self, x):\n","        x = self.patch_embed(x)\n","\n","        for i in range(len(self.transformer_layers)):\n","            x = self.transformer_layers[i](x)\n","            if len(self.mamba_layers) > 0:\n","                for j in range(i * self.mamba_to_transformer_ratio, (i * self.mamba_to_transformer_ratio) + self.mamba_to_transformer_ratio):\n","                    x = self.mamba_layers[j](x)\n","\n","        x = self.final_transformer(x)\n","\n","        x = rearrange(x, \"b (h w) c -> b c h w\", h = 512 // 16)\n","\n","        x = self.decoder_1(x)\n","        x = self.decoder_2(x)\n","        x = self.decoder_3(x)\n","        x = self.decoder_4(x)\n","\n","        x = self.final_out(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"56766017-1a95-459c-a631-f70d598a596e","metadata":{"id":"56766017-1a95-459c-a631-f70d598a596e"},"outputs":[],"source":["def preprocess_data(image, mask, train):\n","    if train:\n","        image_transforms = A.Compose(\n","            [\n","                A.OneOf([\n","                    A.ToGray(),\n","                    A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=3, val_shift_limit=3),\n","                    A.RandomBrightnessContrast(brightness_limit=0.01, contrast_limit=0.01, brightness_by_max=False)\n","                ], p=0.2),\n","                A.Normalize(),\n","                ToTensorV2()\n","            ]\n","        )\n","    else:\n","        image_transforms = A.Compose(\n","            [\n","                A.Normalize(),\n","                ToTensorV2()\n","            ]\n","        )\n","\n","    image = image_transforms(image=image)\n","    image = image['image']\n","\n","    mask = torch.from_numpy(mask)\n","    mask = torch.permute(mask, (2, 0, 1))\n","    mask = mask[0]\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":null,"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","metadata":{"id":"abda32f1-3087-4143-9766-97b4a32dc3c6"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, image_paths, target_paths, preprocess_fn, train=False):\n","        self.image_paths = image_paths\n","        self.target_paths = target_paths\n","        self.preprocess_fn = preprocess_fn\n","        self.train = train\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.image_paths[index])\n","        mask = Image.open(self.target_paths[index])\n","\n","        return self.preprocess_fn(np.array(image), np.array(mask, dtype=np.int8), train=self.train)\n","\n","    def __len__(self):\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":null,"id":"Ht9eqFxI7HaF","metadata":{"id":"Ht9eqFxI7HaF"},"outputs":[],"source":["class DiceLoss(nn.Module):\n","    \"\"\"Dice Loss PyTorch\n","        Created by: Zhang Shuai\n","        Email: shuaizzz666@gmail.com\n","        dice_loss = 1 - 2*p*t / (p^2 + t^2). p and t represent predict and target.\n","    Args:\n","        weight: An array of shape [C,]\n","        predict: A float32 tensor of shape [N, C, *], for Semantic segmentation task is [N, C, H, W]\n","        target: A int64 tensor of shape [N, *], for Semantic segmentation task is [N, H, W]\n","    Return:\n","        diceloss\n","    \"\"\"\n","    def __init__(self, weight=None):\n","        super(DiceLoss, self).__init__()\n","        if weight is not None:\n","            weight = torch.Tensor(weight)\n","            self.weight = weight / torch.sum(weight) # Normalized weight\n","        self.smooth = 1e-5\n","\n","    def forward(self, predict, target):\n","        N, C = predict.size()[:2]\n","        predict = predict.view(N, C, -1) # (N, C, *)\n","        target = target.view(N, 1, -1) # (N, 1, *)\n","\n","        predict = F.softmax(predict, dim=1) # (N, C, *) ==> (N, C, *)\n","        ## convert target(N, 1, *) into one hot vector (N, C, *)\n","        target_onehot = torch.zeros(predict.size()).cuda()  # (N, 1, *) ==> (N, C, *)\n","        target_onehot.scatter_(1, target, 1)  # (N, C, *)\n","\n","        intersection = torch.sum(predict * target_onehot, dim=2)  # (N, C)\n","        union = torch.sum(predict.pow(2), dim=2) + torch.sum(target_onehot, dim=2)  # (N, C)\n","        ## p^2 + t^2 >= 2*p*t, target_onehot^2 == target_onehot\n","        dice_coef = (2 * intersection + self.smooth) / (union + self.smooth)  # (N, C)\n","\n","        if hasattr(self, 'weight'):\n","            if self.weight.type() != predict.type():\n","                self.weight = self.weight.type_as(predict)\n","                dice_coef = dice_coef * self.weight * C  # (N, C)\n","        dice_loss = 1 - torch.mean(dice_coef)  # 1\n","\n","        return dice_loss"]},{"cell_type":"code","execution_count":null,"id":"6pOxcCZN7IaI","metadata":{"id":"6pOxcCZN7IaI"},"outputs":[],"source":["class CEPlusDiceLoss(nn.Module):\n","    def __init__(self):\n","        super(CEPlusDiceLoss, self).__init__()\n","        self.dice_loss = DiceLoss()\n","        self.ce_loss = nn.CrossEntropyLoss()\n","\n","    def forward(self, predict, target):\n","        dice = self.dice_loss(predict, target.to(torch.int64))\n","        ce = self.ce_loss(predict, target.long())\n","\n","        total = dice + ce\n","\n","        return total"]},{"cell_type":"code","execution_count":null,"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","metadata":{"id":"699f2149-d1d7-4d08-bbef-019da2ab4135"},"outputs":[],"source":["batch_size = 8\n","num_epochs = 25\n","num_classes = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","show_summary = True\n","experiment_name = \"2t-5m\"\n","run = 1"]},{"cell_type":"code","execution_count":null,"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","metadata":{"id":"e565ed5e-add1-4153-bf27-f276fc5717bd"},"outputs":[],"source":["train_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/image\", \"*.tif\"))\n","train_img_paths = sorted(train_img_paths)\n","\n","train_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/label\", \"*.tif\"))\n","train_mask_paths = sorted(train_mask_paths)\n","\n","val_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/image\", \"*.tif\"))\n","val_img_paths = sorted(val_img_paths)\n","\n","val_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/label\", \"*.tif\"))\n","val_mask_paths = sorted(val_mask_paths)"]},{"cell_type":"code","execution_count":null,"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","metadata":{"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5"},"outputs":[],"source":["train_dataset = CustomDataset(\n","    image_paths=train_img_paths,\n","    target_paths=train_mask_paths,\n","    preprocess_fn=preprocess_data,\n","    train=True\n",")\n","val_dataset = CustomDataset(\n","    image_paths=val_img_paths,\n","    target_paths=val_mask_paths,\n","    preprocess_fn=preprocess_data,\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","metadata":{"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe"},"outputs":[],"source":["model = SETRM(num_transformer_layers=2, mamba_to_transformer_ratio=5).to(device)\n","loss_fn = CEPlusDiceLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.000001, weight_decay=0.0001)\n","metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":null,"id":"VgC2dd2u8BeM","metadata":{"id":"VgC2dd2u8BeM"},"outputs":[],"source":["if run > 1:\n","    model.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_model-{experiment_name}-run-{run - 1}.pth\"))\n","    print(\"Loading model\")\n","    optimizer.load_state_dict(torch.load(f\"/content/drive/MyDrive/landcover_seg_opt-{experiment_name}-run-{run - 1}.pth\"))\n","    print(\"Loading optimizer\")"]},{"cell_type":"code","execution_count":null,"id":"89a861fb-e509-44a8-b625-f072f40b67be","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"89a861fb-e509-44a8-b625-f072f40b67be","outputId":"2efcb53e-40bb-4a21-b080-eb213d56732f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.9791\n","Train IoU: 0.2800\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.7165\n","Validation IoU: 0.2929\n","-----------------------------\n","Epoch 2/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.7274\n","Train IoU: 0.3520\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.6838\n","Validation IoU: 0.3125\n","-----------------------------\n","Epoch 3/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.5894\n","Train IoU: 0.3902\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4360\n","Validation IoU: 0.3677\n","-----------------------------\n","Epoch 4/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [21:59<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.4833\n","Train IoU: 0.4195\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.3283\n","Validation IoU: 0.3982\n","-----------------------------\n","Epoch 5/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.4005\n","Train IoU: 0.4387\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2679\n","Validation IoU: 0.4080\n","-----------------------------\n","Epoch 6/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.3348\n","Train IoU: 0.4573\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2209\n","Validation IoU: 0.4203\n","-----------------------------\n","Epoch 7/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.2813\n","Train IoU: 0.4702\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1967\n","Validation IoU: 0.4357\n","-----------------------------\n","Epoch 8/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.2339\n","Train IoU: 0.4831\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1222\n","Validation IoU: 0.4576\n","-----------------------------\n","Epoch 9/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.1865\n","Train IoU: 0.4964\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1130\n","Validation IoU: 0.4579\n","-----------------------------\n","Epoch 10/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.1561\n","Train IoU: 0.5024\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.0795\n","Validation IoU: 0.4603\n","-----------------------------\n","Epoch 11/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.1235\n","Train IoU: 0.5123\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.0250\n","Validation IoU: 0.4822\n","-----------------------------\n","Epoch 12/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.1020\n","Train IoU: 0.5175\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 1.0060\n","Validation IoU: 0.4888\n","-----------------------------\n","Epoch 13/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0737\n","Train IoU: 0.5256\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9878\n","Validation IoU: 0.4961\n","-----------------------------\n","Epoch 14/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0409\n","Train IoU: 0.5393\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9906\n","Validation IoU: 0.5018\n","-----------------------------\n","Epoch 15/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0298\n","Train IoU: 0.5387\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9786\n","Validation IoU: 0.5033\n","-----------------------------\n","Epoch 16/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 1.0136\n","Train IoU: 0.5445\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9671\n","Validation IoU: 0.4970\n","-----------------------------\n","Epoch 17/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9981\n","Train IoU: 0.5511\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9556\n","Validation IoU: 0.5063\n","-----------------------------\n","Epoch 18/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9872\n","Train IoU: 0.5530\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9443\n","Validation IoU: 0.5189\n","-----------------------------\n","Epoch 19/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:02<00:00,  1.42s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9681\n","Train IoU: 0.5599\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9343\n","Validation IoU: 0.5074\n","-----------------------------\n","Epoch 20/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.42s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9535\n","Train IoU: 0.5709\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9406\n","Validation IoU: 0.5107\n","-----------------------------\n","Epoch 21/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:02<00:00,  1.42s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9526\n","Train IoU: 0.5656\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9111\n","Validation IoU: 0.5304\n","-----------------------------\n","Epoch 22/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:00<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9368\n","Train IoU: 0.5734\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:47<00:00,  1.87it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.9104\n","Validation IoU: 0.5379\n","-----------------------------\n","Epoch 23/25:\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 934/934 [22:01<00:00,  1.41s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss: 0.9292\n","Train IoU: 0.5751\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Validation: 100%|██████████| 201/201 [01:46<00:00,  1.88it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Validation Loss: 0.8952\n","Validation IoU: 0.5308\n","-----------------------------\n","Epoch 24/25:\n"]},{"output_type":"stream","name":"stderr","text":["Training:  53%|█████▎    | 498/934 [11:44<10:18,  1.42s/it]"]}],"source":["epoch_train_loss = []\n","epoch_train_iou = []\n","epoch_val_loss = []\n","epoch_val_iou = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n","\n","    model.train()\n","    train_loss = 0\n","    train_iou = 0\n","\n","    for images, masks in tqdm(train_loader, desc=\"Training\"):\n","        images, masks = images.to(device), masks.to(device)\n","        outputs = model(images)\n","        loss = loss_fn(outputs, masks)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_iou += metric(outputs, masks)\n","\n","    train_loss = train_loss / len(train_loader)\n","    train_iou = train_iou / len(train_loader)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_train_iou.append(train_iou)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Train IoU: {train_iou:.4f}\")\n","\n","    model.eval()\n","    val_loss = 0\n","    val_iou = 0\n","\n","    with torch.inference_mode():\n","        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n","            images, masks = images.to(device), masks.to(device)\n","\n","            outputs = model(images)\n","            loss = loss_fn(outputs, masks)\n","\n","            val_loss += loss.item()\n","            val_iou += metric(outputs, masks)\n","\n","    val_loss = val_loss / len(val_loader)\n","    val_iou = val_iou / len(val_loader)\n","\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_iou.append(val_iou)\n","\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation IoU: {val_iou:.4f}\")\n","    print(\"-----------------------------\")"]},{"cell_type":"code","execution_count":null,"id":"rCl04L8bdo_g","metadata":{"id":"rCl04L8bdo_g"},"outputs":[],"source":["torch.save(model.state_dict(), f\"/content/drive/MyDrive/landcover_seg_model-{experiment_name}-run-{run}.pth\")\n","torch.save(optimizer.state_dict(), f\"/content/drive/MyDrive/landcover_seg_opt-{experiment_name}-run-{run}.pth\")"]},{"cell_type":"code","execution_count":null,"id":"tp1UZojmbHct","metadata":{"id":"tp1UZojmbHct"},"outputs":[],"source":["training_stats = {\n","    \"train_loss\": epoch_train_loss,\n","    \"train_iou\": [el.item() for el in epoch_train_iou],\n","    \"val_loss\": epoch_val_loss,\n","    \"val_iou\": [el.item() for el in epoch_val_iou]\n","}\n","\n","with open(f\"/content/drive/MyDrive/train-stats-{experiment_name}-run-{run}.json\", \"w\") as outfile:\n","    json.dump(training_stats, outfile)"]},{"cell_type":"code","execution_count":null,"id":"G4DD9sWN3Ao4","metadata":{"id":"G4DD9sWN3Ao4"},"outputs":[],"source":["if show_summary:\n","    print(summary(model, input_size=(1, 3, 512, 512)))"]},{"cell_type":"code","execution_count":null,"id":"cgpcI20j1bUO","metadata":{"id":"cgpcI20j1bUO"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}