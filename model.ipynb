{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB4qserabZXf","executionInfo":{"status":"ok","timestamp":1720299586502,"user_tz":300,"elapsed":1280,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"5afe8863-e979-4d17-da37-0e308412348a"},"id":"vB4qserabZXf","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE6AAvCoVYpP","executionInfo":{"status":"ok","timestamp":1720298363766,"user_tz":300,"elapsed":59456,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"2c518ef6-35f7-47e8-b52a-816f53878fd5"},"id":"pE6AAvCoVYpP","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n","Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.4.0.post0\n"]}]},{"cell_type":"code","source":["!pip install -U torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKkY-CWOkYKE","executionInfo":{"status":"ok","timestamp":1720298419553,"user_tz":300,"elapsed":55795,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"53971ec3-5ba0-4909-c8fa-d2642d46b935"},"id":"hKkY-CWOkYKE","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Collecting torch\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Collecting triton==2.3.1 (from torch)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: triton, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.3.1 triton-2.3.1\n"]}]},{"cell_type":"code","execution_count":2,"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","metadata":{"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","executionInfo":{"status":"ok","timestamp":1720299593518,"user_tz":300,"elapsed":4574,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data.dataset import Dataset\n","from PIL import Image\n","import glob\n","import os\n","import torch.nn.functional as F\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from torchmetrics.classification import MulticlassJaccardIndex\n","import shutil\n","import cv2"]},{"cell_type":"code","source":["!wget https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP433x83Vt9H","executionInfo":{"status":"ok","timestamp":1720298509619,"user_tz":300,"elapsed":83521,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"ead7df3e-60b6-4c22-9d01-aca1a272d861"},"id":"oP433x83Vt9H","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-07-06 20:40:25--  https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip\n","Resolving landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)... 195.78.67.65\n","Connecting to landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)|195.78.67.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1538212277 (1.4G) [application/zip]\n","Saving to: ‘landcover.ai.v1.zip’\n","\n","landcover.ai.v1.zip 100%[===================>]   1.43G  16.8MB/s    in 82s     \n","\n","2024-07-06 20:41:48 (17.8 MB/s) - ‘landcover.ai.v1.zip’ saved [1538212277/1538212277]\n","\n"]}]},{"cell_type":"code","source":["!unzip landcover.ai.v1.zip -d landcover.ai.v1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezexmvBDWLlM","executionInfo":{"status":"ok","timestamp":1720298521294,"user_tz":300,"elapsed":11678,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"d924dc8e-15da-47f5-8e40-4784cd2879ae"},"id":"ezexmvBDWLlM","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  landcover.ai.v1.zip\n","   creating: landcover.ai.v1/images/\n","  inflating: landcover.ai.v1/images/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-D-c-2-4.tif  \n","   creating: landcover.ai.v1/masks/\n","  inflating: landcover.ai.v1/masks/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-D-c-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/masks/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/split.py  \n","  inflating: landcover.ai.v1/test.txt  \n","  inflating: landcover.ai.v1/train.txt  \n","  inflating: landcover.ai.v1/val.txt  \n"]}]},{"cell_type":"code","source":["IMGS_DIR = \"./landcover.ai.v1/images\"\n","MASKS_DIR = \"./landcover.ai.v1/masks\"\n","OUTPUT_DIR = \"./landcover.ai.v1/output\"\n","\n","TARGET_SIZE = 512\n","\n","img_paths = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\n","mask_paths = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n","\n","img_paths.sort()\n","mask_paths.sort()\n","\n","os.makedirs(OUTPUT_DIR)\n","for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n","    img_filename = os.path.splitext(os.path.basename(img_path))[0]\n","    mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n","    img = cv2.imread(img_path)\n","    mask = cv2.imread(mask_path)\n","\n","    assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n","\n","    k = 0\n","    for y in range(0, img.shape[0], TARGET_SIZE):\n","        for x in range(0, img.shape[1], TARGET_SIZE):\n","            img_tile = img[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","            mask_tile = mask[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","\n","            if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n","                out_img_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}.tif\".format(img_filename, k)\n","                )\n","                cv2.imwrite(out_img_path, img_tile)\n","\n","                out_mask_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}_m.tif\".format(mask_filename, k)\n","                )\n","                cv2.imwrite(out_mask_path, mask_tile)\n","\n","            k += 1\n","\n","    print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9mqVGafXk5q","outputId":"ca10b98f-8b04-4d3f-909a-5f98d2bd3551","executionInfo":{"status":"ok","timestamp":1720298793369,"user_tz":300,"elapsed":272084,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"id":"m9mqVGafXk5q","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed M-33-20-D-c-4-2 1/41\n","Processed M-33-20-D-d-3-3 2/41\n","Processed M-33-32-B-b-4-4 3/41\n","Processed M-33-48-A-c-4-4 4/41\n","Processed M-33-7-A-d-2-3 5/41\n","Processed M-33-7-A-d-3-2 6/41\n","Processed M-34-32-B-a-4-3 7/41\n","Processed M-34-32-B-b-1-3 8/41\n","Processed M-34-5-D-d-4-2 9/41\n","Processed M-34-51-C-b-2-1 10/41\n","Processed M-34-51-C-d-4-1 11/41\n","Processed M-34-55-B-b-4-1 12/41\n","Processed M-34-56-A-b-1-4 13/41\n","Processed M-34-6-A-d-2-2 14/41\n","Processed M-34-65-D-a-4-4 15/41\n","Processed M-34-65-D-c-4-2 16/41\n","Processed M-34-65-D-d-4-1 17/41\n","Processed M-34-68-B-a-1-3 18/41\n","Processed M-34-77-B-c-2-3 19/41\n","Processed N-33-104-A-c-1-1 20/41\n","Processed N-33-119-C-c-3-3 21/41\n","Processed N-33-130-A-d-3-3 22/41\n","Processed N-33-130-A-d-4-4 23/41\n","Processed N-33-139-C-d-2-2 24/41\n","Processed N-33-139-C-d-2-4 25/41\n","Processed N-33-139-D-c-1-3 26/41\n","Processed N-33-60-D-c-4-2 27/41\n","Processed N-33-60-D-d-1-2 28/41\n","Processed N-33-96-D-d-1-1 29/41\n","Processed N-34-106-A-b-3-4 30/41\n","Processed N-34-106-A-c-1-3 31/41\n","Processed N-34-140-A-b-3-2 32/41\n","Processed N-34-140-A-b-4-2 33/41\n","Processed N-34-140-A-d-3-4 34/41\n","Processed N-34-140-A-d-4-2 35/41\n","Processed N-34-61-B-a-1-1 36/41\n","Processed N-34-66-C-c-4-3 37/41\n","Processed N-34-77-A-b-1-4 38/41\n","Processed N-34-94-A-b-2-4 39/41\n","Processed N-34-97-C-b-1-2 40/41\n","Processed N-34-97-D-c-2-4 41/41\n"]}]},{"cell_type":"code","source":["train_data_dir = \"landcover.ai.v1/train/image\"\n","train_label_dir = \"landcover.ai.v1/train/label\"\n","\n","val_data_dir = \"landcover.ai.v1/val/image\"\n","val_label_dir = \"landcover.ai.v1/val/label\"\n","\n","test_data_dir = \"landcover.ai.v1/test/image\"\n","test_label_dir = \"landcover.ai.v1/test/label\"\n","\n","paths = [\n","    train_data_dir,\n","    train_label_dir,\n","    val_data_dir,\n","    val_label_dir,\n","    test_data_dir,\n","    test_label_dir,\n","]\n","\n","for p in paths:\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","        print(f\"Folder '{p}' created.\")\n","    else:\n","        print(f\"Folder '{p}' already exists.\")\n","\n","\n","with open(\"landcover.ai.v1/train.txt\") as f:\n","    train_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/val.txt\") as f:\n","    val_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/test.txt\") as f:\n","    test_split = f.read().splitlines()\n","\n","print(\"Train, Val, Test splits count\")\n","print(len(train_split), len(val_split), len(test_split))\n","print(\"Last item of each split\")\n","print(train_split[-1], val_split[-1], test_split[-1])\n","\n","for i in train_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(train_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(train_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in val_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(val_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(val_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in test_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(test_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(test_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","print(\"File copying completed.\")"],"metadata":{"id":"GMVhfETqX3DI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720298804951,"user_tz":300,"elapsed":11585,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"52d9b231-cf4b-4a09-fb84-812827212bfc"},"id":"GMVhfETqX3DI","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder 'landcover.ai.v1/train/image' created.\n","Folder 'landcover.ai.v1/train/label' created.\n","Folder 'landcover.ai.v1/val/image' created.\n","Folder 'landcover.ai.v1/val/label' created.\n","Folder 'landcover.ai.v1/test/image' created.\n","Folder 'landcover.ai.v1/test/label' created.\n","Train, Val, Test splits count\n","7470 1602 1602\n","Last item of each split\n","N-34-97-D-c-2-4_9 N-34-97-D-c-2-4_75 N-34-97-D-c-2-4_77\n","File copying completed.\n"]}]},{"cell_type":"code","execution_count":3,"id":"a93df827-0e31-479c-8fa0-f506d92eee05","metadata":{"id":"a93df827-0e31-479c-8fa0-f506d92eee05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720299594501,"user_tz":300,"elapsed":240,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"eaf84498-b65f-4375-9159-ab7505f77e8d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":5,"id":"ebcdc313-79b7-4192-bf50-e552608ff2a1","metadata":{"id":"ebcdc313-79b7-4192-bf50-e552608ff2a1","executionInfo":{"status":"ok","timestamp":1720299601575,"user_tz":300,"elapsed":218,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n","        super().__init__()\n","        self.norm1 = nn.LayerNorm(dim)\n","        self.attn = nn.MultiheadAttention(dim, num_heads)\n","        self.norm2 = nn.LayerNorm(dim)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(dim, int(dim * mlp_ratio)),\n","            nn.GELU(),\n","            nn.Linear(int(dim * mlp_ratio), dim),\n","        )\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n","        x = x + self.mlp(self.norm2(x))\n","        return x"]},{"cell_type":"code","execution_count":6,"id":"579539d1-52fc-4c36-b2fd-15b9293b6628","metadata":{"id":"579539d1-52fc-4c36-b2fd-15b9293b6628","executionInfo":{"status":"ok","timestamp":1720299601838,"user_tz":300,"elapsed":3,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class TransformerUNet(nn.Module):\n","    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n","        super().__init__()\n","        self.downs = nn.ModuleList()\n","        self.ups = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNet\n","        for feature in features:\n","            self.downs.append(self._double_conv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNet\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n","            )\n","            self.ups.append(self._double_conv(feature * 2, feature))\n","\n","        self.bottleneck = self._double_conv(features[-1], features[-1] * 2)\n","        self.transformer = TransformerBlock(features[-1] * 2, num_heads=8)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def _double_conv(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        # Down part\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        # Bottleneck\n","        x = self.bottleneck(x)\n","\n","        # Apply transformer to the bottleneck\n","        b, c, h, w = x.shape\n","        x = x.flatten(2).permute(2, 0, 1)  # (H*W, B, C)\n","        x = self.transformer(x)\n","        x = x.permute(1, 2, 0).view(b, c, h, w)\n","\n","        # Up part\n","        skip_connections = skip_connections[::-1]\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx // 2]\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx + 1](concat_skip)\n","\n","        return self.final_conv(x)"]},{"cell_type":"code","execution_count":7,"id":"56766017-1a95-459c-a631-f70d598a596e","metadata":{"id":"56766017-1a95-459c-a631-f70d598a596e","executionInfo":{"status":"ok","timestamp":1720299601838,"user_tz":300,"elapsed":3,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["def preprocess_data(image, mask, train):\n","    if train:\n","        image_transforms = A.Compose(\n","            [\n","                A.OneOf([\n","                    A.ToGray(),\n","                    A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=3, val_shift_limit=3),\n","                    A.RandomBrightnessContrast(brightness_limit=0.01, contrast_limit=0.01, brightness_by_max=False)\n","                ], p=0.2),\n","                ToTensorV2()\n","            ]\n","        )\n","    else:\n","        image_transforms = A.Compose(\n","            [\n","                ToTensorV2()\n","            ]\n","        )\n","\n","    image = image_transforms(image=image)\n","    image = image['image']\n","    image = image / 255\n","\n","    mask = torch.from_numpy(mask)\n","    mask = torch.permute(mask, (2, 0, 1))\n","    mask = mask[0]\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":8,"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","metadata":{"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","executionInfo":{"status":"ok","timestamp":1720299601838,"user_tz":300,"elapsed":3,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, image_paths, target_paths, preprocess_fn, train=False):\n","        self.image_paths = image_paths\n","        self.target_paths = target_paths\n","        self.preprocess_fn = preprocess_fn\n","        self.train = train\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.image_paths[index])\n","        mask = Image.open(self.target_paths[index])\n","\n","        return self.preprocess_fn(np.array(image), np.array(mask, dtype=np.int8), train=self.train)\n","\n","    def __len__(self):\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":9,"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","metadata":{"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","executionInfo":{"status":"ok","timestamp":1720299601839,"user_tz":300,"elapsed":4,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["batch_size = 8\n","num_epochs = 10\n","learning_rate = 0.001\n","num_classes = 5  # Including background\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":10,"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","metadata":{"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","executionInfo":{"status":"ok","timestamp":1720299601839,"user_tz":300,"elapsed":4,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["train_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/image\", \"*.tif\"))\n","train_img_paths = sorted(train_img_paths)\n","\n","train_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/label\", \"*.tif\"))\n","train_mask_paths = sorted(train_mask_paths)\n","\n","val_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/image\", \"*.tif\"))\n","val_img_paths = sorted(val_img_paths)\n","\n","val_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/label\", \"*.tif\"))\n","val_mask_paths = sorted(val_mask_paths)"]},{"cell_type":"code","execution_count":11,"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","metadata":{"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","executionInfo":{"status":"ok","timestamp":1720299601839,"user_tz":300,"elapsed":3,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["train_dataset = CustomDataset(\n","    image_paths=train_img_paths,\n","    target_paths=train_mask_paths,\n","    preprocess_fn=preprocess_data,\n","    train=True\n",")\n","val_dataset = CustomDataset(\n","    image_paths=val_img_paths,\n","    target_paths=val_mask_paths,\n","    preprocess_fn=preprocess_data,\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False\n",")"]},{"cell_type":"code","source":["im, ma = train_dataset[9]\n","print(im.shape)\n","print(im.dtype)\n","print(ma.shape)\n","print(ma.dtype)\n","print(ma[0].shape)\n","print(torch.unique(ma[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6lEFeQ2zLdf","executionInfo":{"status":"ok","timestamp":1720299601839,"user_tz":300,"elapsed":3,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"8cac7966-03f5-44a5-f6aa-dba1f8bf03fd"},"id":"f6lEFeQ2zLdf","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 512, 512])\n","torch.float32\n","torch.Size([512, 512])\n","torch.int8\n","torch.Size([512])\n","tensor([0, 2, 4], dtype=torch.int8)\n"]}]},{"cell_type":"code","execution_count":13,"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","metadata":{"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","executionInfo":{"status":"ok","timestamp":1720299602407,"user_tz":300,"elapsed":571,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["model = TransformerUNet(in_channels=3, out_channels=num_classes).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":14,"id":"89a861fb-e509-44a8-b625-f072f40b67be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89a861fb-e509-44a8-b625-f072f40b67be","executionInfo":{"status":"ok","timestamp":1720310672702,"user_tz":300,"elapsed":11070297,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"536a2444-9208-4adc-b508-bad0482b9078"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [16:58<00:00,  1.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.7363\n","Train IoU: 0.2582\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:22<00:00,  2.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.7329\n","Validation IoU: 0.2865\n","-----------------------------\n","Epoch 2/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:04<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6984\n","Train IoU: 0.2704\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.6712\n","Validation IoU: 0.2877\n","-----------------------------\n","Epoch 3/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:03<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6710\n","Train IoU: 0.2807\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5574\n","Validation IoU: 0.2977\n","-----------------------------\n","Epoch 4/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:04<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5899\n","Train IoU: 0.3188\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4951\n","Validation IoU: 0.3129\n","-----------------------------\n","Epoch 5/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:04<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5613\n","Train IoU: 0.3377\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4409\n","Validation IoU: 0.3419\n","-----------------------------\n","Epoch 6/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:03<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5162\n","Train IoU: 0.3553\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:22<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4904\n","Validation IoU: 0.3166\n","-----------------------------\n","Epoch 7/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:03<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4911\n","Train IoU: 0.3676\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4140\n","Validation IoU: 0.3633\n","-----------------------------\n","Epoch 8/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:04<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4827\n","Train IoU: 0.3664\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5484\n","Validation IoU: 0.3154\n","-----------------------------\n","Epoch 9/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:03<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4611\n","Train IoU: 0.3762\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4648\n","Validation IoU: 0.3278\n","-----------------------------\n","Epoch 10/10:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [17:04<00:00,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4547\n","Train IoU: 0.3794\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:23<00:00,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4145\n","Validation IoU: 0.3551\n","-----------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["epoch_train_loss = []\n","epoch_train_iou = []\n","epoch_val_loss = []\n","epoch_val_iou = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n","\n","    model.train()\n","    train_loss = 0\n","    train_iou = 0\n","\n","    for images, masks in tqdm(train_loader, desc=\"Training\"):\n","        images, masks = images.to(device), masks.to(device)\n","        outputs = model(images)\n","        loss = loss_fn(outputs, masks.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_iou += metric(outputs, masks)\n","\n","    train_loss = train_loss / len(train_loader)\n","    train_iou = train_iou / len(train_loader)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_train_iou.append(train_iou)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Train IoU: {train_iou:.4f}\")\n","\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/landcover_seg_model.pth\")\n","\n","    model.eval()\n","    val_loss = 0\n","    val_iou = 0\n","\n","    with torch.inference_mode():\n","        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n","            images, masks = images.to(device), masks.to(device)\n","\n","            outputs = model(images)\n","            loss = loss_fn(outputs, masks.long())\n","\n","            val_loss += loss.item()\n","            val_iou += metric(outputs, masks)\n","\n","    val_loss = val_loss / len(val_loader)\n","    val_iou = val_iou / len(val_loader)\n","\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_iou.append(val_iou)\n","\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation IoU: {val_iou:.4f}\")\n","    print(\"-----------------------------\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}