{"cells":[{"cell_type":"code","execution_count":1,"id":"vB4qserabZXf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17587,"status":"ok","timestamp":1720472599717,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"},"user_tz":300},"id":"vB4qserabZXf","outputId":"34cd1e46-d95a-4c1e-e3c2-008905459c91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"pE6AAvCoVYpP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE6AAvCoVYpP","outputId":"92a02a83-e0b9-4235-fbe5-4b7ca4365414","executionInfo":{"status":"ok","timestamp":1720472661832,"user_tz":300,"elapsed":62116,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/868.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/868.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n","Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.4.0.post0\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":3,"id":"hKkY-CWOkYKE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKkY-CWOkYKE","outputId":"0b64e704-6ef1-48f6-890f-3f1756a20c87","executionInfo":{"status":"ok","timestamp":1720472726304,"user_tz":300,"elapsed":64476,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Collecting torch\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Collecting triton==2.3.1 (from torch)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: triton, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.0\n","    Uninstalling triton-2.3.0:\n","      Successfully uninstalled triton-2.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.0+cu121\n","    Uninstalling torch-2.3.0+cu121:\n","      Successfully uninstalled torch-2.3.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\n","torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.3.1 triton-2.3.1\n"]}],"source":["!pip install -U torch"]},{"cell_type":"code","execution_count":4,"id":"ADpNRFfzRbN4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADpNRFfzRbN4","outputId":"ec9bdc6c-85aa-455c-8e6a-742123f03b07","executionInfo":{"status":"ok","timestamp":1720472747630,"user_tz":300,"elapsed":21329,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mamba-ssm\n","  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n","Collecting ninja (from mamba-ssm)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops (from mamba-ssm)\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.3.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.41.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.5.82)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n","Building wheels for collected packages: mamba-ssm\n","  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323803485 sha256=cd8ee941b25398d90c135d3a180b5dc33e478c98ae4998b61749809beaff947a\n","  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n","Successfully built mamba-ssm\n","Installing collected packages: ninja, einops, mamba-ssm\n","Successfully installed einops-0.8.0 mamba-ssm-2.2.2 ninja-1.11.1.1\n"]}],"source":["!pip install mamba-ssm"]},{"cell_type":"code","execution_count":1,"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","metadata":{"id":"76d9ffe6-2106-4e0e-bac1-4984f88650b0","executionInfo":{"status":"ok","timestamp":1720478338131,"user_tz":300,"elapsed":5373,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from albumentations.pytorch import ToTensorV2\n","import numpy as np\n","from tqdm import tqdm\n","from torch.utils.data.dataset import Dataset\n","from PIL import Image\n","import glob\n","import os\n","import torch.nn.functional as F\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","from torchmetrics.classification import MulticlassJaccardIndex\n","import shutil\n","import cv2\n","from mamba_ssm import Mamba\n","import json"]},{"cell_type":"code","execution_count":6,"id":"oP433x83Vt9H","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP433x83Vt9H","outputId":"df7b6ca7-9c88-471f-d1ce-d0427b981402","executionInfo":{"status":"ok","timestamp":1720472862992,"user_tz":300,"elapsed":107353,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-07-08 21:05:59--  https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip\n","Resolving landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)... 195.78.67.65\n","Connecting to landcover.ai.linuxpolska.com (landcover.ai.linuxpolska.com)|195.78.67.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1538212277 (1.4G) [application/zip]\n","Saving to: ‘landcover.ai.v1.zip’\n","\n","landcover.ai.v1.zip 100%[===================>]   1.43G  13.1MB/s    in 1m 46s  \n","\n","2024-07-08 21:07:47 (13.8 MB/s) - ‘landcover.ai.v1.zip’ saved [1538212277/1538212277]\n","\n"]}],"source":["!wget https://landcover.ai.linuxpolska.com/download/landcover.ai.v1.zip"]},{"cell_type":"code","execution_count":7,"id":"ezexmvBDWLlM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezexmvBDWLlM","outputId":"1b6bf6fc-1c56-4c8a-9b66-1c12a2b5a062","executionInfo":{"status":"ok","timestamp":1720472876345,"user_tz":300,"elapsed":13356,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  landcover.ai.v1.zip\n","   creating: landcover.ai.v1/images/\n","  inflating: landcover.ai.v1/images/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/images/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/images/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/images/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/images/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/images/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/images/N-34-97-D-c-2-4.tif  \n","   creating: landcover.ai.v1/masks/\n","  inflating: landcover.ai.v1/masks/N-33-119-C-c-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-94-A-b-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-a-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-77-B-c-2-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-77-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-b-3-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-a-4-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-d-4-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-56-A-b-1-4.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-b-3-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-d-1-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-60-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-33-104-A-c-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-D-c-2-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-55-B-b-4-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-D-c-1-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-96-D-d-1-1.tif  \n","  inflating: landcover.ai.v1/masks/M-34-68-B-a-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-2-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-61-B-a-1-1.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-140-A-d-3-4.tif  \n","  inflating: landcover.ai.v1/masks/N-33-130-A-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/N-33-139-C-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-5-D-d-4-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-7-A-d-3-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-51-C-b-2-1.tif  \n","  inflating: landcover.ai.v1/masks/M-33-48-A-c-4-4.tif  \n","  inflating: landcover.ai.v1/masks/N-34-66-C-c-4-3.tif  \n","  inflating: landcover.ai.v1/masks/N-34-97-C-b-1-2.tif  \n","  inflating: landcover.ai.v1/masks/M-34-32-B-b-1-3.tif  \n","  inflating: landcover.ai.v1/masks/M-33-32-B-b-4-4.tif  \n","  inflating: landcover.ai.v1/masks/M-34-6-A-d-2-2.tif  \n","  inflating: landcover.ai.v1/masks/M-33-20-D-d-3-3.tif  \n","  inflating: landcover.ai.v1/masks/M-34-65-D-c-4-2.tif  \n","  inflating: landcover.ai.v1/masks/N-34-106-A-c-1-3.tif  \n","  inflating: landcover.ai.v1/split.py  \n","  inflating: landcover.ai.v1/test.txt  \n","  inflating: landcover.ai.v1/train.txt  \n","  inflating: landcover.ai.v1/val.txt  \n"]}],"source":["!unzip landcover.ai.v1.zip -d landcover.ai.v1"]},{"cell_type":"code","execution_count":8,"id":"m9mqVGafXk5q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9mqVGafXk5q","outputId":"3816df98-c80f-4c8e-8b0a-045b0bb03023","executionInfo":{"status":"ok","timestamp":1720473154576,"user_tz":300,"elapsed":278240,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed M-33-20-D-c-4-2 1/41\n","Processed M-33-20-D-d-3-3 2/41\n","Processed M-33-32-B-b-4-4 3/41\n","Processed M-33-48-A-c-4-4 4/41\n","Processed M-33-7-A-d-2-3 5/41\n","Processed M-33-7-A-d-3-2 6/41\n","Processed M-34-32-B-a-4-3 7/41\n","Processed M-34-32-B-b-1-3 8/41\n","Processed M-34-5-D-d-4-2 9/41\n","Processed M-34-51-C-b-2-1 10/41\n","Processed M-34-51-C-d-4-1 11/41\n","Processed M-34-55-B-b-4-1 12/41\n","Processed M-34-56-A-b-1-4 13/41\n","Processed M-34-6-A-d-2-2 14/41\n","Processed M-34-65-D-a-4-4 15/41\n","Processed M-34-65-D-c-4-2 16/41\n","Processed M-34-65-D-d-4-1 17/41\n","Processed M-34-68-B-a-1-3 18/41\n","Processed M-34-77-B-c-2-3 19/41\n","Processed N-33-104-A-c-1-1 20/41\n","Processed N-33-119-C-c-3-3 21/41\n","Processed N-33-130-A-d-3-3 22/41\n","Processed N-33-130-A-d-4-4 23/41\n","Processed N-33-139-C-d-2-2 24/41\n","Processed N-33-139-C-d-2-4 25/41\n","Processed N-33-139-D-c-1-3 26/41\n","Processed N-33-60-D-c-4-2 27/41\n","Processed N-33-60-D-d-1-2 28/41\n","Processed N-33-96-D-d-1-1 29/41\n","Processed N-34-106-A-b-3-4 30/41\n","Processed N-34-106-A-c-1-3 31/41\n","Processed N-34-140-A-b-3-2 32/41\n","Processed N-34-140-A-b-4-2 33/41\n","Processed N-34-140-A-d-3-4 34/41\n","Processed N-34-140-A-d-4-2 35/41\n","Processed N-34-61-B-a-1-1 36/41\n","Processed N-34-66-C-c-4-3 37/41\n","Processed N-34-77-A-b-1-4 38/41\n","Processed N-34-94-A-b-2-4 39/41\n","Processed N-34-97-C-b-1-2 40/41\n","Processed N-34-97-D-c-2-4 41/41\n"]}],"source":["IMGS_DIR = \"./landcover.ai.v1/images\"\n","MASKS_DIR = \"./landcover.ai.v1/masks\"\n","OUTPUT_DIR = \"./landcover.ai.v1/output\"\n","\n","TARGET_SIZE = 512\n","\n","img_paths = glob.glob(os.path.join(IMGS_DIR, \"*.tif\"))\n","mask_paths = glob.glob(os.path.join(MASKS_DIR, \"*.tif\"))\n","\n","img_paths.sort()\n","mask_paths.sort()\n","\n","os.makedirs(OUTPUT_DIR)\n","for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n","    img_filename = os.path.splitext(os.path.basename(img_path))[0]\n","    mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n","    img = cv2.imread(img_path)\n","    mask = cv2.imread(mask_path)\n","\n","    assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n","\n","    k = 0\n","    for y in range(0, img.shape[0], TARGET_SIZE):\n","        for x in range(0, img.shape[1], TARGET_SIZE):\n","            img_tile = img[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","            mask_tile = mask[y : y + TARGET_SIZE, x : x + TARGET_SIZE]\n","\n","            if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n","                out_img_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}.tif\".format(img_filename, k)\n","                )\n","                cv2.imwrite(out_img_path, img_tile)\n","\n","                out_mask_path = os.path.join(\n","                    OUTPUT_DIR, \"{}_{}_m.tif\".format(mask_filename, k)\n","                )\n","                cv2.imwrite(out_mask_path, mask_tile)\n","\n","            k += 1\n","\n","    print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"]},{"cell_type":"code","execution_count":9,"id":"GMVhfETqX3DI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMVhfETqX3DI","outputId":"15b19b07-ec22-4e98-885b-7a871261f9a7","executionInfo":{"status":"ok","timestamp":1720473164516,"user_tz":300,"elapsed":9555,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Folder 'landcover.ai.v1/train/image' created.\n","Folder 'landcover.ai.v1/train/label' created.\n","Folder 'landcover.ai.v1/val/image' created.\n","Folder 'landcover.ai.v1/val/label' created.\n","Folder 'landcover.ai.v1/test/image' created.\n","Folder 'landcover.ai.v1/test/label' created.\n","Train, Val, Test splits count\n","7470 1602 1602\n","Last item of each split\n","N-34-97-D-c-2-4_9 N-34-97-D-c-2-4_75 N-34-97-D-c-2-4_77\n","File copying completed.\n"]}],"source":["train_data_dir = \"landcover.ai.v1/train/image\"\n","train_label_dir = \"landcover.ai.v1/train/label\"\n","\n","val_data_dir = \"landcover.ai.v1/val/image\"\n","val_label_dir = \"landcover.ai.v1/val/label\"\n","\n","test_data_dir = \"landcover.ai.v1/test/image\"\n","test_label_dir = \"landcover.ai.v1/test/label\"\n","\n","paths = [\n","    train_data_dir,\n","    train_label_dir,\n","    val_data_dir,\n","    val_label_dir,\n","    test_data_dir,\n","    test_label_dir,\n","]\n","\n","for p in paths:\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","        print(f\"Folder '{p}' created.\")\n","    else:\n","        print(f\"Folder '{p}' already exists.\")\n","\n","\n","with open(\"landcover.ai.v1/train.txt\") as f:\n","    train_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/val.txt\") as f:\n","    val_split = f.read().splitlines()\n","\n","with open(\"landcover.ai.v1/test.txt\") as f:\n","    test_split = f.read().splitlines()\n","\n","print(\"Train, Val, Test splits count\")\n","print(len(train_split), len(val_split), len(test_split))\n","print(\"Last item of each split\")\n","print(train_split[-1], val_split[-1], test_split[-1])\n","\n","for i in train_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(train_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(train_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in val_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(val_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(val_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","for i in test_split:\n","    source_file_img = os.path.join(\"landcover.ai.v1/output\", f\"{i}.tif\")\n","    source_file_label = os.path.join(\"landcover.ai.v1/output\", f\"{i}_m.tif\")\n","    destination_file_img = os.path.join(test_data_dir, f\"{i}.tif\")\n","    destination_file_label = os.path.join(test_label_dir, f\"{i}.tif\")\n","    if os.path.isfile(source_file_img) and not os.path.exists(destination_file_img):\n","        shutil.copy2(source_file_img, destination_file_img)\n","    if os.path.isfile(source_file_label) and not os.path.exists(destination_file_label):\n","        shutil.copy2(source_file_label, destination_file_label)\n","\n","print(\"File copying completed.\")"]},{"cell_type":"code","execution_count":3,"id":"a93df827-0e31-479c-8fa0-f506d92eee05","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a93df827-0e31-479c-8fa0-f506d92eee05","outputId":"427d62f0-d887-4ef2-8b95-fcebecfb0cbb","executionInfo":{"status":"ok","timestamp":1720478343642,"user_tz":300,"elapsed":389,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":4,"id":"ebcdc313-79b7-4192-bf50-e552608ff2a1","metadata":{"id":"ebcdc313-79b7-4192-bf50-e552608ff2a1","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":7,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n","        super().__init__()\n","        self.norm1 = nn.LayerNorm(dim)\n","        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n","        self.norm2 = nn.LayerNorm(dim)\n","        self.mlp = nn.Sequential(\n","            nn.Linear(dim, int(dim * mlp_ratio)),\n","            nn.GELU(),\n","            nn.Linear(int(dim * mlp_ratio), dim)\n","        )\n","\n","    def forward(self, x):\n","        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n","        x = x + self.mlp(self.norm2(x))\n","        return x"]},{"cell_type":"code","execution_count":5,"id":"579539d1-52fc-4c36-b2fd-15b9293b6628","metadata":{"id":"579539d1-52fc-4c36-b2fd-15b9293b6628","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":7,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class MambaTransformerUNet(nn.Module):\n","    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n","        super().__init__()\n","        self.downs = nn.ModuleList()\n","        self.ups = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.mamba_layers = nn.ModuleList()\n","\n","        for feature in features:\n","            self.downs.append(self._double_conv(in_channels, feature))\n","            in_channels = feature\n","\n","        for feature in reversed(features):\n","            self.ups.append(\n","                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n","            )\n","            self.ups.append(self._double_conv(feature * 2, feature))\n","            self.mamba_layers.append(Mamba(d_model=feature, d_state=16, d_conv=4, expand=2))\n","\n","        self.bottleneck = self._double_conv(features[-1], features[-1] * 2)\n","        self.transformer = TransformerBlock(features[-1] * 2, num_heads=8)\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def _double_conv(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        skip_connections = []\n","\n","        for idx, down in enumerate(self.downs):\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","\n","        b, c, h, w = x.shape\n","        x = x.flatten(2).permute(0, 2, 1) # (B, H*W, C)\n","        x = self.transformer(x)\n","        x = x.permute(0, 2, 1).view(b, c, h, w)\n","\n","        skip_connections = skip_connections[::-1]\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx // 2]\n","\n","            b, c, h, w = skip_connection.shape\n","            skip_connection = skip_connection.flatten(2).permute(0, 2, 1) # (B, H*W, C)\n","            skip_connection = self.mamba_layers[idx // 2](skip_connection)\n","            skip_connection = skip_connection.permute(0, 2, 1).view(b, c, h, w)\n","\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx + 1](concat_skip)\n","\n","        return self.final_conv(x)"]},{"cell_type":"code","execution_count":6,"id":"56766017-1a95-459c-a631-f70d598a596e","metadata":{"id":"56766017-1a95-459c-a631-f70d598a596e","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":7,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["def preprocess_data(image, mask, train):\n","    if train:\n","        image_transforms = A.Compose(\n","            [\n","                A.OneOf([\n","                    A.ToGray(),\n","                    A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=3, val_shift_limit=3),\n","                    A.RandomBrightnessContrast(brightness_limit=0.01, contrast_limit=0.01, brightness_by_max=False)\n","                ], p=0.2),\n","                ToTensorV2()\n","            ]\n","        )\n","    else:\n","        image_transforms = A.Compose(\n","            [\n","                ToTensorV2()\n","            ]\n","        )\n","\n","    image = image_transforms(image=image)\n","    image = image['image']\n","    image = image / 255\n","\n","    mask = torch.from_numpy(mask)\n","    mask = torch.permute(mask, (2, 0, 1))\n","    mask = mask[0]\n","\n","    return image, mask"]},{"cell_type":"code","execution_count":7,"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","metadata":{"id":"abda32f1-3087-4143-9766-97b4a32dc3c6","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":7,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, image_paths, target_paths, preprocess_fn, train=False):\n","        self.image_paths = image_paths\n","        self.target_paths = target_paths\n","        self.preprocess_fn = preprocess_fn\n","        self.train = train\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.image_paths[index])\n","        mask = Image.open(self.target_paths[index])\n","\n","        return self.preprocess_fn(np.array(image), np.array(mask, dtype=np.int8), train=self.train)\n","\n","    def __len__(self):\n","        return len(self.image_paths)"]},{"cell_type":"code","execution_count":8,"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","metadata":{"id":"699f2149-d1d7-4d08-bbef-019da2ab4135","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":6,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["batch_size = 8\n","num_epochs = 90\n","num_classes = 5  # Including background\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","continue_training = False"]},{"cell_type":"code","execution_count":9,"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","metadata":{"id":"e565ed5e-add1-4153-bf27-f276fc5717bd","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":6,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["train_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/image\", \"*.tif\"))\n","train_img_paths = sorted(train_img_paths)\n","\n","train_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/train/label\", \"*.tif\"))\n","train_mask_paths = sorted(train_mask_paths)\n","\n","val_img_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/image\", \"*.tif\"))\n","val_img_paths = sorted(val_img_paths)\n","\n","val_mask_paths = glob.glob(os.path.join(\"landcover.ai.v1/val/label\", \"*.tif\"))\n","val_mask_paths = sorted(val_mask_paths)"]},{"cell_type":"code","execution_count":10,"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","metadata":{"id":"04b67689-e34f-4a2b-adb8-fe2ea4f7e4b5","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":6,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["train_dataset = CustomDataset(\n","    image_paths=train_img_paths,\n","    target_paths=train_mask_paths,\n","    preprocess_fn=preprocess_data,\n","    train=True\n",")\n","val_dataset = CustomDataset(\n","    image_paths=val_img_paths,\n","    target_paths=val_mask_paths,\n","    preprocess_fn=preprocess_data,\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False\n",")"]},{"cell_type":"code","execution_count":11,"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","metadata":{"id":"c1e4f8b5-d6bb-4d95-b388-cafddb3068fe","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":6,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["model = MambaTransformerUNet(in_channels=3, out_channels=num_classes).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters())\n","metric = MulticlassJaccardIndex(num_classes=num_classes).to(device)"]},{"cell_type":"code","execution_count":12,"id":"962bwljVfO2q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"962bwljVfO2q","executionInfo":{"status":"ok","timestamp":1720478344449,"user_tz":300,"elapsed":6,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"fb287b52-3769-4c1f-edd6-69fa3560752e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting from scratch\n"]}],"source":["if continue_training:\n","    print(\"Loading saved model\")\n","    model.load_state_dict(torch.load(\"/content/drive/MyDrive/landcover_seg_model.pth\"))\n","    optimizer.load_state_dict(torch.load(\"/content/drive/MyDrive/landcover_seg_opt.pth\"))\n","else:\n","    print(\"Starting from scratch\")"]},{"cell_type":"code","execution_count":13,"id":"89a861fb-e509-44a8-b625-f072f40b67be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89a861fb-e509-44a8-b625-f072f40b67be","executionInfo":{"status":"ok","timestamp":1720480470321,"user_tz":300,"elapsed":2125877,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}},"outputId":"fabc4cea-ac19-4262-9227-b5ba18a6a4c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [10:46<00:00,  1.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6741\n","Train IoU: 0.2846\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:01<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.5652\n","Validation IoU: 0.3063\n","-----------------------------\n","Epoch 2/3:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [10:44<00:00,  1.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5155\n","Train IoU: 0.3538\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:01<00:00,  3.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4330\n","Validation IoU: 0.3552\n","-----------------------------\n","Epoch 3/3:\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|██████████| 934/934 [10:44<00:00,  1.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.4492\n","Train IoU: 0.3958\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 201/201 [01:01<00:00,  3.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.3500\n","Validation IoU: 0.3763\n","-----------------------------\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["epoch_train_loss = []\n","epoch_train_iou = []\n","epoch_val_loss = []\n","epoch_val_iou = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n","\n","    model.train()\n","    train_loss = 0\n","    train_iou = 0\n","\n","    for images, masks in tqdm(train_loader, desc=\"Training\"):\n","        images, masks = images.to(device), masks.to(device)\n","        outputs = model(images)\n","        loss = loss_fn(outputs, masks.long())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_iou += metric(outputs, masks)\n","\n","    train_loss = train_loss / len(train_loader)\n","    train_iou = train_iou / len(train_loader)\n","\n","    epoch_train_loss.append(train_loss)\n","    epoch_train_iou.append(train_iou)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Train IoU: {train_iou:.4f}\")\n","\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/landcover_seg_model.pth\")\n","    torch.save(optimizer.state_dict(), \"/content/drive/MyDrive/landcover_seg_opt.pth\")\n","\n","    model.eval()\n","    val_loss = 0\n","    val_iou = 0\n","\n","    with torch.inference_mode():\n","        for images, masks in tqdm(val_loader, desc=\"Validation\"):\n","            images, masks = images.to(device), masks.to(device)\n","\n","            outputs = model(images)\n","            loss = loss_fn(outputs, masks.long())\n","\n","            val_loss += loss.item()\n","            val_iou += metric(outputs, masks)\n","\n","    val_loss = val_loss / len(val_loader)\n","    val_iou = val_iou / len(val_loader)\n","\n","    epoch_val_loss.append(val_loss)\n","    epoch_val_iou.append(val_iou)\n","\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation IoU: {val_iou:.4f}\")\n","    print(\"-----------------------------\")"]},{"cell_type":"code","execution_count":14,"id":"tp1UZojmbHct","metadata":{"id":"tp1UZojmbHct","executionInfo":{"status":"ok","timestamp":1720480470735,"user_tz":300,"elapsed":425,"user":{"displayName":"Kunal Gurnani","userId":"00052946301797653631"}}},"outputs":[],"source":["training_stats = {\n","    \"train_loss\": epoch_train_loss,\n","    \"train_iou\": [el.item() for el in epoch_train_iou],\n","    \"val_loss\": epoch_val_loss,\n","    \"val_iou\": [el.item() for el in epoch_val_iou]\n","}\n","\n","with open(\"/content/drive/MyDrive/mrp-train-stats.json\", \"w\") as outfile:\n","    json.dump(training_stats, outfile)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":5}